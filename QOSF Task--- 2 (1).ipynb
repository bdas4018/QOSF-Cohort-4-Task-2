{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fourth-monroe",
   "metadata": {},
   "source": [
    "### Imported the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "friendly-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-tomato",
   "metadata": {},
   "source": [
    "### Constructed the variational circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "neural-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits in the circuit\n",
    "nr_qubits = 4\n",
    "# number of layers in the circuit\n",
    "nr_layers = 2\n",
    "\n",
    "# randomly initialize parameters from a normal distribution\n",
    "params = np.random.normal(0, np.pi, (nr_qubits*4, nr_layers, 4))\n",
    "params = Variable(torch.tensor(params), requires_grad=True)\n",
    "\n",
    "# a layer of the circuit ansatz\n",
    "def layer(params, j):\n",
    "    \n",
    "    for i in range(nr_qubits):\n",
    "        qml.RX(params[i, j, 0], wires=i)\n",
    "        qml.RY(params[i, j, 1], wires=i)\n",
    "        qml.RZ(params[i, j, 2], wires=i)\n",
    "        qml.RZ(params[i, j, 3], wires=i)\n",
    "        \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[1, 3])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "downtown-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5605, -0.4344,  2.0348,  4.7847],\n",
       "         [-0.7356, -0.7356,  4.9612,  2.4110]],\n",
       "\n",
       "        [[-1.4749,  1.7045, -1.4559, -1.4631],\n",
       "         [ 0.7601, -6.0107, -5.4190, -1.7665]],\n",
       "\n",
       "        [[-3.1819,  0.9872, -2.8526, -4.4369],\n",
       "         [ 4.6045, -0.7093,  0.2121, -4.4760]],\n",
       "\n",
       "        [[-1.7102,  0.3485, -3.6160,  1.1803],\n",
       "         [-1.8870, -0.9164, -1.8903,  5.8191]],\n",
       "\n",
       "        [[-0.0424, -3.3229,  2.5841, -3.8354],\n",
       "         [ 0.6562, -6.1565, -4.1726,  0.6185]],\n",
       "\n",
       "        [[ 2.3200,  0.5384, -0.3633, -0.9459],\n",
       "         [-4.6449, -2.2615, -1.4471,  3.3210]],\n",
       "\n",
       "        [[ 1.0795, -5.5388,  1.0181, -1.2098],\n",
       "         [-2.1266,  1.9216,  3.2390,  2.9257]],\n",
       "\n",
       "        [[-2.6365, -0.9714,  1.0407,  3.0648],\n",
       "         [-1.5054, -0.5833, -3.4757, -3.7580]],\n",
       "\n",
       "        [[ 2.5526,  4.2608, -0.2262,  3.1527],\n",
       "         [ 1.1361, -2.0267,  1.1354,  4.8319]],\n",
       "\n",
       "        [[-0.1126,  4.9155, -8.2302,  2.5821],\n",
       "         [ 0.2735, -0.9394,  0.2883, -6.2441]],\n",
       "\n",
       "        [[-0.6901,  1.1219,  4.6429, -1.6282],\n",
       "         [-2.5400, -1.5763,  2.8758,  1.0328]],\n",
       "\n",
       "        [[-1.6643,  1.6125,  0.3050,  3.0431],\n",
       "         [-2.2056, -1.0294, -1.2318, -4.5978]],\n",
       "\n",
       "        [[ 0.9303,  0.8201,  0.0161, -0.7370],\n",
       "         [-4.4465, -1.3215, -1.0767, -2.5204]],\n",
       "\n",
       "        [[-0.5067,  1.2694,  5.9256,  0.5485],\n",
       "         [ 0.8091, -0.2339, -6.0280, -0.0833]],\n",
       "\n",
       "        [[ 0.1892,  7.7385, -0.6043,  0.9473],\n",
       "         [-0.1091, -3.6715,  3.5903,  2.3623]],\n",
       "\n",
       "        [[ 2.4851, -2.8569,  4.4070, -4.4040],\n",
       "         [ 1.8437,  6.8815, -3.1119, -1.7791]]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-positive",
   "metadata": {},
   "source": [
    "### We use the \"default.qubit\" device to perform the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polish-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit(params, A,input_1):\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    qml.QubitStateVector(input_1, wires=[0,1,2,3])\n",
    "        \n",
    "  \n",
    "        \n",
    "        \n",
    "    \n",
    "    # repeatedly apply each layer in the circuit\n",
    "    for j in range(nr_layers):\n",
    "        layer(params, j)\n",
    "    \n",
    "    # measure the expectation value for each wire\n",
    "    a=qml.expval(qml.Hermitian(A, wires=0))\n",
    "    b=qml.expval(qml.Hermitian(A, wires=1))\n",
    "    c=qml.expval(qml.Hermitian(A, wires=2))\n",
    "    d=qml.expval(qml.Hermitian(A, wires=3))\n",
    "    \n",
    "\n",
    "    \n",
    "    # returns the expectation of the input matrix A on the first qubit:      \n",
    "    return a,b,c,d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-lesbian",
   "metadata": {},
   "source": [
    "### Prepare a random state-vector on 4 qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complex-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20889538+0.08235256j, -0.03927539+0.16413401j,\n",
       "         0.01705947+0.03113048j,  0.16858427+0.26197478j,\n",
       "        -0.31613047+0.20626543j,  0.04069385+0.02418946j,\n",
       "        -0.3536006 +0.14878745j,  0.07084692-0.15233711j,\n",
       "        -0.01948252+0.23750527j, -0.22589945+0.16266235j,\n",
       "         0.01636915-0.23158514j, -0.35253193+0.04063286j,\n",
       "         0.07828291-0.29178605j,  0.01716371-0.16414925j,\n",
       "        -0.06432171+0.14734933j,  0.18813903-0.09383527j],\n",
       "       [ 0.03209248-0.23957826j,  0.13043321-0.127946j  ,\n",
       "         0.26388014+0.18854133j,  0.01573879+0.01468668j,\n",
       "         0.28077312-0.28359107j, -0.08439142-0.12695547j,\n",
       "        -0.01416332-0.23236245j,  0.08652411+0.04140239j,\n",
       "         0.0329493 +0.13733234j, -0.03226748-0.13910798j,\n",
       "         0.0091103 +0.16859443j, -0.09566516+0.21953481j,\n",
       "        -0.12679844+0.32075745j,  0.19197097+0.07725978j,\n",
       "         0.26076317-0.27984902j, -0.34966845+0.00981328j],\n",
       "       [-0.24780512+0.12790782j, -0.31394969+0.05104097j,\n",
       "        -0.06404581-0.24820189j,  0.06823676-0.02893227j,\n",
       "         0.0784306 +0.29005042j, -0.08205914+0.05793702j,\n",
       "        -0.14031113-0.15504586j,  0.01136186+0.21939646j,\n",
       "         0.11548864+0.15363129j,  0.16541171-0.25813577j,\n",
       "        -0.07677636-0.10456713j,  0.37262629+0.14651517j,\n",
       "         0.01881243+0.03085258j, -0.27679522+0.12793329j,\n",
       "         0.0417596 -0.2694139j ,  0.16313836+0.23278856j],\n",
       "       [ 0.13886462+0.29354912j,  0.15532048+0.17196482j,\n",
       "        -0.30681668+0.2575446j ,  0.1862979 -0.19549095j,\n",
       "        -0.24812663+0.11710429j,  0.24873998+0.10454558j,\n",
       "         0.11202201-0.11117272j, -0.15368195-0.18285822j,\n",
       "        -0.09030855-0.19803765j,  0.02592689-0.21484798j,\n",
       "         0.06822827-0.31726382j, -0.02336129+0.08041861j,\n",
       "         0.12854388-0.01967147j, -0.22066785+0.12635548j,\n",
       "        -0.20051748-0.19762084j,  0.07797188+0.06302849j]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit import quantum_info as qf\n",
    "rand_sv_1=np.array(qf.random_statevector(16))\n",
    "rand_sv_2=np.array(qf.random_statevector(16))\n",
    "rand_sv_3=np.array(qf.random_statevector(16))\n",
    "rand_sv_4=np.array(qf.random_statevector(16))\n",
    "\n",
    "rand_sv_f= np.array([rand_sv_1,rand_sv_2,rand_sv_3,rand_sv_4])\n",
    "\n",
    "\n",
    "rand_sv_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-decrease",
   "metadata": {},
   "source": [
    "### Prepare the cost function and the optimisation routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "owned-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 steps is 8.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\torch\\autograd\\__init__.py:147: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ..\\aten\\src\\ATen\\native\\Copy.cpp:240.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 10 steps is 8.3036\n",
      "Cost after 20 steps is 8.0826\n",
      "Cost after 30 steps is 7.8637\n",
      "Cost after 40 steps is 7.6593\n",
      "Cost after 50 steps is 7.4567\n",
      "Cost after 60 steps is 7.2544\n",
      "Cost after 70 steps is 7.0828\n",
      "Cost after 80 steps is 6.9044\n",
      "Cost after 90 steps is 6.7516\n",
      "Cost after 100 steps is 6.6033\n",
      "Cost after 110 steps is 6.4614\n",
      "Cost after 120 steps is 6.3238\n",
      "Cost after 130 steps is 6.1948\n",
      "Cost after 140 steps is 6.0670\n",
      "Cost after 150 steps is 5.9462\n",
      "Cost after 160 steps is 5.8271\n",
      "Cost after 170 steps is 5.7134\n",
      "Cost after 180 steps is 5.6137\n",
      "Cost after 190 steps is 5.5153\n",
      "Cost after 200 steps is 5.4208\n",
      "Cost after 210 steps is 5.3297\n",
      "Cost after 220 steps is 5.2388\n",
      "Cost after 230 steps is 5.1499\n",
      "Cost after 240 steps is 5.0782\n",
      "Cost after 250 steps is 5.0064\n",
      "Cost after 260 steps is 4.9379\n",
      "Cost after 270 steps is 4.8683\n",
      "Cost after 280 steps is 4.8006\n",
      "Cost after 290 steps is 4.7332\n",
      "Cost after 300 steps is 4.6669\n",
      "Cost after 310 steps is 4.6010\n",
      "Cost after 320 steps is 4.5353\n",
      "Cost after 330 steps is 4.4688\n",
      "Cost after 340 steps is 4.4048\n",
      "Cost after 350 steps is 4.3401\n",
      "Cost after 360 steps is 4.2744\n",
      "Cost after 370 steps is 4.2104\n",
      "Cost after 380 steps is 4.1468\n",
      "Cost after 390 steps is 4.0844\n",
      "Cost after 400 steps is 4.0194\n",
      "Cost after 410 steps is 3.9575\n",
      "Cost after 420 steps is 3.8938\n",
      "Cost after 430 steps is 3.8327\n",
      "Cost after 440 steps is 3.7758\n",
      "Cost after 450 steps is 3.7187\n",
      "Cost after 460 steps is 3.6632\n",
      "Cost after 470 steps is 3.6068\n",
      "Cost after 480 steps is 3.5515\n",
      "Cost after 490 steps is 3.4968\n",
      "Cost after 500 steps is 3.4403\n",
      "Cost after 510 steps is 3.3863\n",
      "Cost after 520 steps is 3.3324\n",
      "Cost after 530 steps is 3.2789\n",
      "Cost after 540 steps is 3.2271\n",
      "Cost after 550 steps is 3.1726\n",
      "Cost after 560 steps is 3.1208\n",
      "Cost after 570 steps is 3.0705\n",
      "Cost after 580 steps is 3.0214\n",
      "Cost after 590 steps is 2.9716\n",
      "Cost after 600 steps is 2.9222\n",
      "Cost after 610 steps is 2.8759\n",
      "Cost after 620 steps is 2.8298\n",
      "Cost after 630 steps is 2.7838\n",
      "Cost after 640 steps is 2.7405\n",
      "Cost after 650 steps is 2.6976\n",
      "Cost after 660 steps is 2.6564\n",
      "Cost after 670 steps is 2.6161\n",
      "Cost after 680 steps is 2.5776\n",
      "Cost after 690 steps is 2.5406\n",
      "Cost after 700 steps is 2.5038\n",
      "Cost after 710 steps is 2.4690\n",
      "Cost after 720 steps is 2.4350\n",
      "Cost after 730 steps is 2.4027\n",
      "Cost after 740 steps is 2.3710\n",
      "Cost after 750 steps is 2.3407\n",
      "Cost after 760 steps is 2.3107\n",
      "Cost after 770 steps is 2.2815\n",
      "Cost after 780 steps is 2.2536\n",
      "Cost after 790 steps is 2.2262\n",
      "Cost after 800 steps is 2.1981\n",
      "Cost after 810 steps is 2.1710\n",
      "Cost after 820 steps is 2.1450\n",
      "Cost after 830 steps is 2.1175\n",
      "Cost after 840 steps is 2.0917\n",
      "Cost after 850 steps is 2.0657\n",
      "Cost after 860 steps is 2.0389\n",
      "Cost after 870 steps is 2.0150\n",
      "Cost after 880 steps is 1.9877\n",
      "Cost after 890 steps is 1.9627\n",
      "Cost after 900 steps is 1.9384\n",
      "Cost after 910 steps is 1.9127\n",
      "Cost after 920 steps is 1.8868\n",
      "Cost after 930 steps is 1.8618\n",
      "Cost after 940 steps is 1.8370\n",
      "Cost after 950 steps is 1.8129\n",
      "Cost after 960 steps is 1.7876\n",
      "Cost after 970 steps is 1.7641\n",
      "Cost after 980 steps is 1.7403\n",
      "Cost after 990 steps is 1.7168\n",
      "Cost after 1000 steps is 1.6938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Paulis = Variable(torch.zeros([4, 2, 2], dtype=torch.complex128), requires_grad=False)\n",
    "\n",
    "# Use Pauli-Z as the Hermitian operator\n",
    "Paulis[0] = torch.tensor([[1, 0], [0, -1]])\n",
    "Paulis[1] = torch.tensor([[1, 0], [0, -1]])\n",
    "Paulis[2] = torch.tensor([[1, 0], [0, -1]])\n",
    "Paulis[3] = torch.tensor([[1, 0], [0, -1]])\n",
    "\n",
    "\n",
    "## Required o/ps\n",
    "## Rows are the required output states\n",
    "bloch_v=np.array([[0,1,0,1],\n",
    "                  [0,0,1,1],\n",
    "                  [1,0,1,0],\n",
    "                  [1,1,0,0]])   \n",
    "   \n",
    "    \n",
    "\n",
    "## Cost function\n",
    "def cost_fn(params):\n",
    "    f=0\n",
    "    tt=np.zeros(4)\n",
    "    for input_1 in range(4):\n",
    "        a,b,c,d=circuit(params[4*input_1:(4*input_1)+4], Paulis[0],rand_sv_f[input_1])\n",
    "        tt=[a,b,c,d]\n",
    "        \n",
    "        for k in range(4):\n",
    "                     \n",
    "            f+=torch.abs(tt[k] - bloch_v[input_1][k])\n",
    "     \n",
    "        \n",
    "       \n",
    "    return (f)\n",
    "\n",
    "\n",
    "\n",
    "#set up the optimizer\n",
    "opt = torch.optim.Adam([params], lr=0.001)\n",
    "\n",
    "# number of steps in the optimization routine\n",
    "steps = 1000\n",
    "\n",
    "# the final stage of optimization isn't always the best, so we keep track of\n",
    "# the best parameters along the way\n",
    "best_cost = cost_fn(params)\n",
    "best_params = np.zeros((nr_qubits*4, nr_layers, 4))\n",
    "\n",
    "print(\"Cost after 0 steps is {:.4f}\".format(cost_fn(params)))\n",
    "\n",
    "# optimization begins\n",
    "for n in range(steps):\n",
    "    opt.zero_grad()\n",
    "    loss = cost_fn(params)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # keeps track of best parameters\n",
    "    if loss < best_cost:\n",
    "        best_cost = loss\n",
    "        best_params = params\n",
    "\n",
    "    # Keep track of progress every 10 steps\n",
    "    if n % 10 == 9 or n == steps - 1:\n",
    "        print(\"Cost after {} steps is {:.4f}\".format(n + 1, loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-carter",
   "metadata": {},
   "source": [
    "### Print the o/p results and compare with the desired o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "selected-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after training :\n",
      "[tensor([-8.6769e-05,  8.7489e-01, -9.4963e-05,  8.2369e-01],\n",
      "       dtype=torch.float64, grad_fn=<CatBackward>), tensor([-4.2521e-04,  1.5763e-04,  6.8000e-01,  6.9708e-01],\n",
      "       dtype=torch.float64, grad_fn=<CatBackward>), tensor([ 7.6410e-01, -1.3571e-05,  8.8403e-01,  4.8339e-05],\n",
      "       dtype=torch.float64, grad_fn=<CatBackward>), tensor([ 9.0984e-01,  6.7684e-01,  3.1843e-04, -3.9108e-04],\n",
      "       dtype=torch.float64, grad_fn=<CatBackward>)]\n",
      "Desired o/p :\n",
      "[[0 1 0 1]\n",
      " [0 0 1 1]\n",
      " [1 0 1 0]\n",
      " [1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "output_bloch_v = [0,0,0,0]\n",
    "for input_1 in range(4):\n",
    "    output_bloch_v[input_1] = circuit(best_params[4*input_1:(4*input_1)+4], Paulis[0],rand_sv_f[input_1])\n",
    "        \n",
    "\n",
    "\n",
    "# o/p after training\n",
    "print(\"Output after training :\")\n",
    "print(output_bloch_v)\n",
    "\n",
    "# desired o/p\n",
    "print(\"Desired o/p :\")\n",
    "print(bloch_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-person",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-accounting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-status",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-potential",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-costa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-swimming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-cache",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-genetics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-language",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-combat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-northeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-chick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
