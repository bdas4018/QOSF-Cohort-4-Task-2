{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "variable-helmet",
   "metadata": {},
   "source": [
    "### Imported the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "friendly-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\numpy\\.libs\\libopenblas.JPIJNSWNNAN3CE6LLI5FWSPHUT2VXMTH.gfortran-win_amd64.dll\n",
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-patrick",
   "metadata": {},
   "source": [
    "### Constructed the variational circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "neural-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits in the circuit\n",
    "nr_qubits = 4\n",
    "# number of layers in the circuit\n",
    "nr_layers = 2\n",
    "\n",
    "# randomly initialize parameters from a normal distribution\n",
    "params = np.random.normal(0, np.pi, (nr_qubits*4, nr_layers, 4))\n",
    "params = Variable(torch.tensor(params), requires_grad=True)\n",
    "\n",
    "# a layer of the circuit ansatz\n",
    "def layer(params, j):\n",
    "    \n",
    "    for i in range(nr_qubits):\n",
    "        qml.RX(params[i, j, 0], wires=i)\n",
    "        qml.RY(params[i, j, 1], wires=i)\n",
    "        qml.RZ(params[i, j, 2], wires=i)\n",
    "        qml.RZ(params[i, j, 3], wires=i)\n",
    "        \n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[1, 3])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "editorial-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5605, -0.4344,  2.0348,  4.7847],\n",
       "         [-0.7356, -0.7356,  4.9612,  2.4110]],\n",
       "\n",
       "        [[-1.4749,  1.7045, -1.4559, -1.4631],\n",
       "         [ 0.7601, -6.0107, -5.4190, -1.7665]],\n",
       "\n",
       "        [[-3.1819,  0.9872, -2.8526, -4.4369],\n",
       "         [ 4.6045, -0.7093,  0.2121, -4.4760]],\n",
       "\n",
       "        [[-1.7102,  0.3485, -3.6160,  1.1803],\n",
       "         [-1.8870, -0.9164, -1.8903,  5.8191]],\n",
       "\n",
       "        [[-0.0424, -3.3229,  2.5841, -3.8354],\n",
       "         [ 0.6562, -6.1565, -4.1726,  0.6185]],\n",
       "\n",
       "        [[ 2.3200,  0.5384, -0.3633, -0.9459],\n",
       "         [-4.6449, -2.2615, -1.4471,  3.3210]],\n",
       "\n",
       "        [[ 1.0795, -5.5388,  1.0181, -1.2098],\n",
       "         [-2.1266,  1.9216,  3.2390,  2.9257]],\n",
       "\n",
       "        [[-2.6365, -0.9714,  1.0407,  3.0648],\n",
       "         [-1.5054, -0.5833, -3.4757, -3.7580]],\n",
       "\n",
       "        [[ 2.5526,  4.2608, -0.2262,  3.1527],\n",
       "         [ 1.1361, -2.0267,  1.1354,  4.8319]],\n",
       "\n",
       "        [[-0.1126,  4.9155, -8.2302,  2.5821],\n",
       "         [ 0.2735, -0.9394,  0.2883, -6.2441]],\n",
       "\n",
       "        [[-0.6901,  1.1219,  4.6429, -1.6282],\n",
       "         [-2.5400, -1.5763,  2.8758,  1.0328]],\n",
       "\n",
       "        [[-1.6643,  1.6125,  0.3050,  3.0431],\n",
       "         [-2.2056, -1.0294, -1.2318, -4.5978]],\n",
       "\n",
       "        [[ 0.9303,  0.8201,  0.0161, -0.7370],\n",
       "         [-4.4465, -1.3215, -1.0767, -2.5204]],\n",
       "\n",
       "        [[-0.5067,  1.2694,  5.9256,  0.5485],\n",
       "         [ 0.8091, -0.2339, -6.0280, -0.0833]],\n",
       "\n",
       "        [[ 0.1892,  7.7385, -0.6043,  0.9473],\n",
       "         [-0.1091, -3.6715,  3.5903,  2.3623]],\n",
       "\n",
       "        [[ 2.4851, -2.8569,  4.4070, -4.4040],\n",
       "         [ 1.8437,  6.8815, -3.1119, -1.7791]]], dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-brick",
   "metadata": {},
   "source": [
    "### We use the \"default.qubit\" device to perform the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polish-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit(params, A,input_1):\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    qml.QubitStateVector(input_1, wires=[0,1,2,3])\n",
    "        \n",
    "  \n",
    "        \n",
    "        \n",
    "    \n",
    "    # repeatedly apply each layer in the circuit\n",
    "    for j in range(nr_layers):\n",
    "        layer(params, j)\n",
    "    \n",
    "    # measure the expectation value for each of the 4 qubits\n",
    "    a=qml.expval(qml.Hermitian(A, wires=0))\n",
    "    b=qml.expval(qml.Hermitian(A, wires=1))\n",
    "    c=qml.expval(qml.Hermitian(A, wires=2))\n",
    "    d=qml.expval(qml.Hermitian(A, wires=3))\n",
    "    \n",
    "\n",
    "    \n",
    "     \n",
    "    return a,b,c,d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-motivation",
   "metadata": {},
   "source": [
    "### Prepare 4 random state-vectors (on 4 qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complex-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0957305 +0.07856306j,  0.04760377+0.1092431j ,\n",
       "         0.19821649-0.40359278j, -0.14414241+0.19370413j,\n",
       "        -0.18510572+0.09015012j,  0.18887678-0.20250999j,\n",
       "         0.02374265+0.21173011j, -0.03058101+0.09743701j,\n",
       "        -0.0011431 +0.16597834j,  0.27659039-0.21551254j,\n",
       "        -0.02495377-0.01257104j, -0.17457162+0.10333173j,\n",
       "        -0.17643418-0.05441784j,  0.29649044+0.11901455j,\n",
       "        -0.07878079-0.32799366j,  0.01821124+0.3039391j ],\n",
       "       [-0.20576799-0.06968409j,  0.0740323 -0.12148095j,\n",
       "        -0.11951468+0.08697454j, -0.20117197+0.069j     ,\n",
       "         0.07987179-0.29709208j,  0.08735282+0.18202656j,\n",
       "        -0.10865751+0.20239454j,  0.22146178-0.12153324j,\n",
       "        -0.04641685+0.12215511j, -0.04035463+0.03191758j,\n",
       "        -0.17598089-0.01289915j, -0.01468281-0.05960108j,\n",
       "        -0.49896617+0.13751242j, -0.04311746+0.04246193j,\n",
       "        -0.00099926+0.09646897j,  0.28284838-0.44498996j],\n",
       "       [-0.24597721+0.06379617j, -0.01366898+0.35412976j,\n",
       "        -0.27954391-0.21834315j, -0.12846252-0.09263625j,\n",
       "        -0.19064138-0.2629462j , -0.19865798-0.10394591j,\n",
       "        -0.03545318-0.23594007j, -0.00494826-0.26014336j,\n",
       "        -0.10495956+0.05181871j, -0.0162749 +0.16263981j,\n",
       "         0.37878679+0.08980191j, -0.21088895-0.05521166j,\n",
       "         0.24971327-0.04540047j,  0.03171617+0.11553946j,\n",
       "         0.04407929+0.05304463j, -0.01151109+0.23537766j],\n",
       "       [-0.28020917+0.11425974j, -0.0913882 +0.17899619j,\n",
       "         0.1568918 -0.09358536j, -0.03514613-0.0393897j ,\n",
       "         0.02088825+0.12927662j, -0.00176513+0.20822956j,\n",
       "         0.0629794 +0.11336666j, -0.17513217+0.02493164j,\n",
       "         0.26091461+0.03526469j,  0.18723166+0.27503159j,\n",
       "         0.21488652+0.08108539j,  0.25478133+0.05090513j,\n",
       "        -0.11452111-0.11626769j, -0.4717459 -0.10692166j,\n",
       "         0.02033465+0.00425301j, -0.35853752+0.18272628j]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qiskit import quantum_info as qf\n",
    "rand_sv_1=np.array(qf.random_statevector(16)) # Statevector correspondong to first 4-qubit random state\n",
    "rand_sv_2=np.array(qf.random_statevector(16)) # Statevector correspondong to second 4-qubit random state\n",
    "rand_sv_3=np.array(qf.random_statevector(16)) # Statevector correspondong to third 4-qubit random state\n",
    "rand_sv_4=np.array(qf.random_statevector(16)) # Statevector correspondong to fourth 4-qubit random state\n",
    "\n",
    "rand_sv_f= np.array([rand_sv_1,rand_sv_2,rand_sv_3,rand_sv_4]) # Put all of them in a single array\n",
    "\n",
    "\n",
    "rand_sv_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-senate",
   "metadata": {},
   "source": [
    "### Prepare the cost function and the optimisation routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "owned-copper",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 steps is 8.8018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhargav\\anaconda3\\envs\\Qiskit_1\\lib\\site-packages\\torch\\autograd\\__init__.py:147: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ..\\aten\\src\\ATen\\native\\Copy.cpp:240.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 10 steps is 8.5847\n",
      "Cost after 20 steps is 8.3463\n",
      "Cost after 30 steps is 8.1117\n",
      "Cost after 40 steps is 7.8951\n",
      "Cost after 50 steps is 7.6846\n",
      "Cost after 60 steps is 7.4825\n",
      "Cost after 70 steps is 7.2966\n",
      "Cost after 80 steps is 7.1365\n",
      "Cost after 90 steps is 6.9885\n",
      "Cost after 100 steps is 6.8483\n",
      "Cost after 110 steps is 6.7303\n",
      "Cost after 120 steps is 6.6130\n",
      "Cost after 130 steps is 6.4998\n",
      "Cost after 140 steps is 6.3880\n",
      "Cost after 150 steps is 6.2770\n",
      "Cost after 160 steps is 6.1683\n",
      "Cost after 170 steps is 6.0593\n",
      "Cost after 180 steps is 5.9491\n",
      "Cost after 190 steps is 5.8390\n",
      "Cost after 200 steps is 5.7473\n",
      "Cost after 210 steps is 5.6619\n",
      "Cost after 220 steps is 5.5788\n",
      "Cost after 230 steps is 5.4970\n",
      "Cost after 240 steps is 5.4139\n",
      "Cost after 250 steps is 5.3333\n",
      "Cost after 260 steps is 5.2539\n",
      "Cost after 270 steps is 5.1749\n",
      "Cost after 280 steps is 5.0974\n",
      "Cost after 290 steps is 5.0212\n",
      "Cost after 300 steps is 4.9440\n",
      "Cost after 310 steps is 4.8703\n",
      "Cost after 320 steps is 4.7946\n",
      "Cost after 330 steps is 4.7215\n",
      "Cost after 340 steps is 4.6474\n",
      "Cost after 350 steps is 4.5746\n",
      "Cost after 360 steps is 4.5143\n",
      "Cost after 370 steps is 4.4619\n",
      "Cost after 380 steps is 4.4089\n",
      "Cost after 390 steps is 4.3600\n",
      "Cost after 400 steps is 4.3128\n",
      "Cost after 410 steps is 4.2653\n",
      "Cost after 420 steps is 4.2178\n",
      "Cost after 430 steps is 4.1727\n",
      "Cost after 440 steps is 4.1272\n",
      "Cost after 450 steps is 4.0818\n",
      "Cost after 460 steps is 4.0369\n",
      "Cost after 470 steps is 3.9938\n",
      "Cost after 480 steps is 3.9516\n",
      "Cost after 490 steps is 3.9067\n",
      "Cost after 500 steps is 3.8633\n",
      "Cost after 510 steps is 3.8208\n",
      "Cost after 520 steps is 3.7805\n",
      "Cost after 530 steps is 3.7384\n",
      "Cost after 540 steps is 3.6958\n",
      "Cost after 550 steps is 3.6554\n",
      "Cost after 560 steps is 3.6149\n",
      "Cost after 570 steps is 3.5751\n",
      "Cost after 580 steps is 3.5362\n",
      "Cost after 590 steps is 3.4991\n",
      "Cost after 600 steps is 3.4608\n",
      "Cost after 610 steps is 3.4237\n",
      "Cost after 620 steps is 3.3875\n",
      "Cost after 630 steps is 3.3529\n",
      "Cost after 640 steps is 3.3160\n",
      "Cost after 650 steps is 3.2818\n",
      "Cost after 660 steps is 3.2495\n",
      "Cost after 670 steps is 3.2157\n",
      "Cost after 680 steps is 3.1837\n",
      "Cost after 690 steps is 3.1517\n",
      "Cost after 700 steps is 3.1217\n",
      "Cost after 710 steps is 3.0907\n",
      "Cost after 720 steps is 3.0603\n",
      "Cost after 730 steps is 3.0349\n",
      "Cost after 740 steps is 3.0059\n",
      "Cost after 750 steps is 2.9768\n",
      "Cost after 760 steps is 2.9488\n",
      "Cost after 770 steps is 2.9246\n",
      "Cost after 780 steps is 2.8980\n",
      "Cost after 790 steps is 2.8724\n",
      "Cost after 800 steps is 2.8502\n",
      "Cost after 810 steps is 2.8255\n",
      "Cost after 820 steps is 2.8009\n",
      "Cost after 830 steps is 2.7780\n",
      "Cost after 840 steps is 2.7570\n",
      "Cost after 850 steps is 2.7352\n",
      "Cost after 860 steps is 2.7147\n",
      "Cost after 870 steps is 2.6938\n",
      "Cost after 880 steps is 2.6742\n",
      "Cost after 890 steps is 2.6567\n",
      "Cost after 900 steps is 2.6385\n",
      "Cost after 910 steps is 2.6189\n",
      "Cost after 920 steps is 2.5992\n",
      "Cost after 930 steps is 2.5806\n",
      "Cost after 940 steps is 2.5643\n",
      "Cost after 950 steps is 2.5473\n",
      "Cost after 960 steps is 2.5305\n",
      "Cost after 970 steps is 2.5139\n",
      "Cost after 980 steps is 2.4996\n",
      "Cost after 990 steps is 2.4844\n",
      "Cost after 1000 steps is 2.4704\n",
      "Cost after 1010 steps is 2.4541\n",
      "Cost after 1020 steps is 2.4402\n",
      "Cost after 1030 steps is 2.4258\n",
      "Cost after 1040 steps is 2.4116\n",
      "Cost after 1050 steps is 2.3979\n",
      "Cost after 1060 steps is 2.3858\n",
      "Cost after 1070 steps is 2.3727\n",
      "Cost after 1080 steps is 2.3584\n",
      "Cost after 1090 steps is 2.3482\n",
      "Cost after 1100 steps is 2.3350\n",
      "Cost after 1110 steps is 2.3215\n",
      "Cost after 1120 steps is 2.3106\n",
      "Cost after 1130 steps is 2.2985\n",
      "Cost after 1140 steps is 2.2864\n",
      "Cost after 1150 steps is 2.2753\n",
      "Cost after 1160 steps is 2.2664\n",
      "Cost after 1170 steps is 2.2536\n",
      "Cost after 1180 steps is 2.2453\n",
      "Cost after 1190 steps is 2.2365\n",
      "Cost after 1200 steps is 2.2239\n",
      "Cost after 1210 steps is 2.2136\n",
      "Cost after 1220 steps is 2.2033\n",
      "Cost after 1230 steps is 2.1928\n",
      "Cost after 1240 steps is 2.1819\n",
      "Cost after 1250 steps is 2.1724\n",
      "Cost after 1260 steps is 2.1623\n",
      "Cost after 1270 steps is 2.1515\n",
      "Cost after 1280 steps is 2.1426\n",
      "Cost after 1290 steps is 2.1345\n",
      "Cost after 1300 steps is 2.1257\n",
      "Cost after 1310 steps is 2.1162\n",
      "Cost after 1320 steps is 2.1083\n",
      "Cost after 1330 steps is 2.0978\n",
      "Cost after 1340 steps is 2.0907\n",
      "Cost after 1350 steps is 2.0824\n",
      "Cost after 1360 steps is 2.0733\n",
      "Cost after 1370 steps is 2.0657\n",
      "Cost after 1380 steps is 2.0587\n",
      "Cost after 1390 steps is 2.0491\n",
      "Cost after 1400 steps is 2.0408\n",
      "Cost after 1410 steps is 2.0325\n",
      "Cost after 1420 steps is 2.0265\n",
      "Cost after 1430 steps is 2.0172\n",
      "Cost after 1440 steps is 2.0097\n",
      "Cost after 1450 steps is 2.0021\n",
      "Cost after 1460 steps is 1.9937\n",
      "Cost after 1470 steps is 1.9886\n",
      "Cost after 1480 steps is 1.9802\n",
      "Cost after 1490 steps is 1.9727\n",
      "Cost after 1500 steps is 1.9653\n",
      "Cost after 1510 steps is 1.9589\n",
      "Cost after 1520 steps is 1.9544\n",
      "Cost after 1530 steps is 1.9449\n",
      "Cost after 1540 steps is 1.9372\n",
      "Cost after 1550 steps is 1.9302\n",
      "Cost after 1560 steps is 1.9228\n",
      "Cost after 1570 steps is 1.9161\n",
      "Cost after 1580 steps is 1.9102\n",
      "Cost after 1590 steps is 1.9047\n",
      "Cost after 1600 steps is 1.8964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Paulis = Variable(torch.zeros([4, 2, 2], dtype=torch.complex128), requires_grad=False)\n",
    "\n",
    "# Use Pauli-Z as the Hermitian operator\n",
    "Paulis[0] = torch.tensor([[1, 0], [0, -1]])\n",
    "Paulis[1] = torch.tensor([[1, 0], [0, -1]])\n",
    "Paulis[2] = torch.tensor([[1, 0], [0, -1]])\n",
    "Paulis[3] = torch.tensor([[1, 0], [0, -1]])\n",
    "\n",
    "\n",
    "## Required o/ps - Rows are the required output states\n",
    "bloch_v=np.array([[0,0,1,1],\n",
    "                  [0,1,0,1],\n",
    "                  [1,0,1,0],\n",
    "                  [1,1,0,0]])   \n",
    "   \n",
    "    \n",
    "\n",
    "## Cost function\n",
    "def cost_fn(params):\n",
    "    f=0\n",
    "    tt=np.zeros(4)\n",
    "    for input_1 in range(4):\n",
    "        a,b,c,d=circuit(params[4*input_1:(4*input_1)+4], Paulis[0],rand_sv_f[input_1])\n",
    "        tt=[a,b,c,d]\n",
    "        \n",
    "        for k in range(4):\n",
    "                     \n",
    "            f+=torch.abs(tt[k] - bloch_v[input_1][k])\n",
    "     \n",
    "        \n",
    "       \n",
    "    return (f)\n",
    "\n",
    "\n",
    "\n",
    "#set up the optimizer\n",
    "opt = torch.optim.Adam([params], lr=0.001)\n",
    "\n",
    "# number of steps in the optimization routine\n",
    "steps = 1600\n",
    "\n",
    "# the final stage of optimization isn't always the best, so we keep track of\n",
    "# the best parameters along the way\n",
    "best_cost = cost_fn(params)\n",
    "best_params = np.zeros((nr_qubits*4, nr_layers, 4))\n",
    "\n",
    "print(\"Cost after 0 steps is {:.4f}\".format(cost_fn(params)))\n",
    "\n",
    "# optimization begins\n",
    "for n in range(steps):\n",
    "    opt.zero_grad()\n",
    "    loss = cost_fn(params)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # keeps track of best parameters\n",
    "    if loss < best_cost:\n",
    "        best_cost = loss\n",
    "        best_params = params\n",
    "\n",
    "    # Keep track of progress every 10 steps\n",
    "    if n % 10 == 9 or n == steps - 1:\n",
    "        print(\"Cost after {} steps is {:.4f}\".format(n + 1, loss))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-nomination",
   "metadata": {},
   "source": [
    "### Print the o/p results and compare with the desired o/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "selected-judgment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after training :\n",
      "[tensor([4.2476e-04, 6.5946e-04, 7.7024e-01, 8.0605e-01], dtype=torch.float64,\n",
      "       grad_fn=<CatBackward>), tensor([-8.6857e-06,  9.1285e-01, -5.8013e-04,  6.4734e-01],\n",
      "       dtype=torch.float64, grad_fn=<CatBackward>), tensor([ 7.1885e-01, -2.1761e-05,  6.4423e-01, -1.0951e-04],\n",
      "       dtype=torch.float64, grad_fn=<CatBackward>), tensor([ 8.9348e-01,  7.1323e-01, -5.9763e-04, -1.0939e-04],\n",
      "       dtype=torch.float64, grad_fn=<CatBackward>)]\n",
      "Desired o/p :\n",
      "[[0 0 1 1]\n",
      " [0 1 0 1]\n",
      " [1 0 1 0]\n",
      " [1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "output_bloch_v = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "for input_1 in range(4):\n",
    "    output_bloch_v[input_1] = circuit(best_params[4*input_1:(4*input_1)+4], Paulis[0],rand_sv_f[input_1])\n",
    "        \n",
    "\n",
    "\n",
    "# o/p after training\n",
    "print(\"Output after training :\")\n",
    "print(output_bloch_v)\n",
    "\n",
    "# desired o/p\n",
    "print(\"Desired o/p :\")\n",
    "print(bloch_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-person",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-accounting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-formula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-binary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-appearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-drilling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-theater",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-chambers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-george",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-production",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-worse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
